{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cb0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('train.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f275cab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "      <td>156060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4079.732744</td>\n",
       "      <td>2.063578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45050.785842</td>\n",
       "      <td>2502.764394</td>\n",
       "      <td>0.893832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39015.750000</td>\n",
       "      <td>1861.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78030.500000</td>\n",
       "      <td>4017.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>117045.250000</td>\n",
       "      <td>6244.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>156060.000000</td>\n",
       "      <td>8544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PhraseId     SentenceId      Sentiment\n",
       "count  156060.000000  156060.000000  156060.000000\n",
       "mean    78030.500000    4079.732744       2.063578\n",
       "std     45050.785842    2502.764394       0.893832\n",
       "min         1.000000       1.000000       0.000000\n",
       "25%     39015.750000    1861.750000       2.000000\n",
       "50%     78030.500000    4017.000000       2.000000\n",
       "75%    117045.250000    6244.000000       3.000000\n",
       "max    156060.000000    8544.000000       4.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e8edb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   PhraseId    156060 non-null  int64 \n",
      " 1   SentenceId  156060 non-null  int64 \n",
      " 2   Phrase      156060 non-null  object\n",
      " 3   Sentiment   156060 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0178fe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment value counts\n",
    "data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a0f3a",
   "metadata": {},
   "source": [
    "To proceed further with the sentiment analysis we need to do text classification. We can use 'bag of words (BOW)' model for the analysis. In laymen terms BOW model converts text in the form of numbers which can then be used in an algorithm for analysis.\n",
    "\n",
    "Specifically BOW model is used for feature extraction in text data. It returns a vector with all the words and number of times each word is repeated. It is known as BOW because it is only concerned with the number of times a word is repeated rather than order of words. Let's take an example to understand it better (assume each document contains a sentence only):\n",
    "\n",
    "Doc1: Switzerland is a beautiful country. \n",
    "Doc2: India is a country of smart IT professionals. \n",
    "Doc3: USA is a country of opportunities. \n",
    "\n",
    "More the content in each document lengthier would be the length of each vector (will contain lot of zeros). Basically doc vectors would be a sparse vectors if documents are too large. Sparse vectors need lot of memory for storage and due to length even computation becomes slow. In order to reduce the length of the sparse vectors one may use the technique like stemming, lematization, converting to lower case or ignoring stop-words e.t.c.\n",
    "\n",
    "Now, we will generate DTM using CountVectorizer module of scikit-learn. To read more about the arguments of CountVectorizer you may visit here. As discussed above we will use:\n",
    "\n",
    "tokenizer = Overrides the string tokenization step, we generatre tokenizer from NLTK's Regex tokenizer (by default: None)\n",
    "lowercase = True (no need to use, as it is set True by default)\n",
    "stop_words = 'english' (by default None is used, to improve the result we can provide custom made list of stop words)\n",
    "ngram_range = (1,1) (by defualt its (1,1) i.e strictly monograms will be used, (2,2) only bigrams while (1,2) uses both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0761c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(data['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b3ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['Sentiment'], test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a1e3b",
   "metadata": {},
   "source": [
    "Now we have the training and testing data. We should start the analysis. Our analysis (as most of ML analysis) will be in 5 steps(a mneumonic to remember them is DC-FEM remember as DC Female or District of Columbia Fire and Emergency Medical service):\n",
    "\n",
    "1. Defining the model\n",
    "2. Compiling the model\n",
    "3. Fitting the model\n",
    "4. Evaluating the model\n",
    "5. Making predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcfca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we use the sklearn naive bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6749485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.25%\n"
     ]
    }
   ],
   "source": [
    "#evaluating the nb model\n",
    "\n",
    "from sklearn import metrics\n",
    "predicted = MNB.predict(X_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, Y_test)\n",
    "\n",
    "\n",
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c157e44",
   "metadata": {},
   "source": [
    "### Trying different n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f5fe8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.42%\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.feature_extraction import CountVectorizer\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#token = RegexpTokenizer(r'[A-Za-z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (2,2), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(data['Phrase'])\n",
    "\n",
    "#from sklearn.model_selection import train_test_split()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['Sentiment'],test_size=0.25, random_state=5)\n",
    "\n",
    "#Defining the model-> we will use MultinomialNB\n",
    "\n",
    "#Compiling the model -> We will import precompiled MNB from sklearn library\n",
    "#from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "#Fitting the model\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, Y_train)\n",
    "\n",
    "#Evaulating the model\n",
    "#form sklearn import metrics\n",
    "accuracy_score = metrics.accuracy_score(MNB.predict(X_test), Y_test)\n",
    "print(str('{:04.2f}'.format(accuracy_score*100))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e37201",
   "metadata": {},
   "source": [
    "TF-IDF: Term Frequency-Inverse Document Frequency\n",
    "Let's use TF-IDF here product of term frequency and inverse document frequency is used. Term frequency is how frequently a terms has appeared in a document. Let's say a term appears f times in a document with d words.\n",
    "Term Frequency = f/d\n",
    "IDF is inverse document frequency. If a corpus contains N documents and the term of our interest appears only in D documents then IDF is:\n",
    "IDF = log(N/D) TF-IDF is product of Term Frequncy and Inverse Document Frequency. TF-IDF shows the rarity of a word in the corpus. If a word is rare then probably its a signature word for a particular sentiment/information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3a42b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score_lsvc = 63.89%\n",
      "accuracy_score_sgdc = 56.48%\n",
      "accuracy_score_lsvc_cv = 62.67%\n",
      "accuracy_score_sgdc_cv = 56.56%\n"
     ]
    }
   ],
   "source": [
    "#trying different non bayesian algorithms\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, data['Sentiment'], test_size=0.25, random_state=2)\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "text_count_2 = tfidf.fit_transform(data['Phrase'])\n",
    "\n",
    "#splitting the data in test and training\n",
    "#from sklearn.model_selection() import train_test_split()\n",
    "x_train, x_test, y_train, y_test = train_test_split(text_count_2, data['Sentiment'],test_size=0.25,random_state=5)\n",
    "\n",
    "SGDC = SGDClassifier()\n",
    "LSVC = LinearSVC()\n",
    "\n",
    "#on TF-IDF data\n",
    "LSVC.fit(x_train, y_train)\n",
    "accuracy_score_lsvc = metrics.accuracy_score(LSVC.predict(x_test), y_test)\n",
    "print('accuracy_score_lsvc = '+str('{:4.2f}'.format(accuracy_score_lsvc*100))+'%')\n",
    "\n",
    "SGDC.fit(x_train, y_train)\n",
    "accuracy_score_sgdc = metrics.accuracy_score(SGDC.predict(x_test), y_test)\n",
    "print('accuracy_score_sgdc = '+str('{:4.2f}'.format(accuracy_score_sgdc*100))+'%')\n",
    "\n",
    "#on CountVectorize data\n",
    "LSVC.fit(X_train, Y_train)\n",
    "accuracy_score_lsvc_CV = metrics.accuracy_score(LSVC.predict(X_test), Y_test)\n",
    "print('accuracy_score_lsvc_cv = '+str('{:4.2f}'.format(accuracy_score_lsvc_CV*100))+'%')\n",
    "\n",
    "SGDC.fit(X_train, Y_train)\n",
    "accuracy_score_sgdc_CV = metrics.accuracy_score(SGDC.predict(X_test), Y_test)\n",
    "print('accuracy_score_sgdc_cv = '+str('{:4.2f}'.format(accuracy_score_sgdc_CV*100))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f5d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
