{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f387b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e6ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the training and test datasets into their respective dataframes\n",
    "trained = pd.read_csv('train_clean.csv')\n",
    "test = pd.read_csv('test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac468e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>amsterdam ewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>ITproblems link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>today staff  MSP took customer service new le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>yet receive assistance one agents securing ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>let change reservation online Im wasting time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Sentiment                                              Tweet\n",
       "0           0   neutral                                    amsterdam ewr  \n",
       "1           1  negative                                   ITproblems link \n",
       "2           2  positive   today staff  MSP took customer service new le...\n",
       "3           3  negative   yet receive assistance one agents securing ne...\n",
       "4           4  negative     let change reservation online Im wasting time "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d646ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>jump DallasAustin market  News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>Chicago seen seat A AA  So far great ride On ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>need bag bouncer Get together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>Hey Jetblue stranded entire plane supposed go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>Big fail curbside baggage Pittsburgh charge  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Sentiment                                              Tweet\n",
       "0           0   neutral                    jump DallasAustin market  News \n",
       "1           1  positive   Chicago seen seat A AA  So far great ride On ...\n",
       "2           2  negative                      need bag bouncer Get together\n",
       "3           3  negative   Hey Jetblue stranded entire plane supposed go...\n",
       "4           4  negative   Big fail curbside baggage Pittsburgh charge  ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbf0e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in Training Data: 12416\n",
      "Unique words in Test Data: 5814\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "train_unique = (list(set(trained['Tweet'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in training data's Tweet column\n",
    "train_unique_words = len(train_unique)\n",
    "\n",
    "#Test Data\n",
    "test_unique = (list(set(test['Tweet'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in test data's Tweet column\n",
    "test_unique_words = len(test_unique)\n",
    "\n",
    "print(\"Unique words in Training Data: {}\".format(train_unique_words))\n",
    "print(\"Unique words in Test Data: {}\".format(test_unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085b776",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d7a884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "train_matrix = [] # Forming a 2D matrix to store all training feature vectors\n",
    "\n",
    "#Test Data\n",
    "test_matrix = [] # Forming a 2D matrix to store all test feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cade60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data: Extracting features and storing them into the training feature matrix\n",
    "for sentence in trained['Tweet']:\n",
    "    train_featurevec = []\n",
    "    word = sentence.split()\n",
    "    for w in train_unique:\n",
    "        train_featurevec.append(word.count(w))\n",
    "    train_matrix.append(train_featurevec)\n",
    "\n",
    "#Test Data: Extracting features and storing them into the test feature matrix\n",
    "for sentence in test['Tweet']:\n",
    "    test_featurevec = []\n",
    "    word = sentence.split()\n",
    "    for w in train_unique:\n",
    "        test_featurevec.append(word.count(w))\n",
    "    test_matrix.append(test_featurevec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1765bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Matrix: (11680 , 12416)\n",
      "Shape of Test Matrix: (2921 , 12416)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training Matrix: ({0} , {1})\".format(len(train_matrix),len(train_matrix[0])))\n",
    "print(\"Shape of Test Matrix: ({0} , {1})\".format(len(test_matrix),len(test_matrix[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "368c6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating distances between every test instance with all the train instances. This returns a 2D distances vector.\n",
    "dists = cdist(test_matrix,train_matrix,'euclidean') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf2516f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2921, 11680)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making an empty column in our test data for predicted labels.\n",
    "test['Predicted Label'] = ''\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5430dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that takes a list and returns the mode of the list. If there are more than one modes, it randomly selects any of them.\n",
    "def get_mode(l):\n",
    "    counting = Counter(l)\n",
    "    max_count = max(counting.values())\n",
    "    return choice([ks for ks in counting if counting[ks] == max_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2aeca",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors & Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e7ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a general structure of our confusion matrix\n",
    "cmatrix = pd.DataFrame({'Gold Positive': '', 'Gold Neutral': '', 'Gold Negative': ''},\n",
    "                       index = ['Predicted Positive','Predicted Neutral','Predicted Negative'])\n",
    "\n",
    "# Lists that will later store respective values for plotting\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "F1_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d0086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmatrix_measures(k,dists,test,cmatrix):\n",
    "\n",
    "  row_count = 0\n",
    "  first_max = 0\n",
    "  second_max = 0\n",
    "  check_tie = False\n",
    "\n",
    "  for ls in dists:\n",
    "    sorted_distances_indices = np.argsort(ls) #Getting a sorted list of indices of all distances in ls with the smallest distance's index at 0th position\n",
    "    knn_indices = []\n",
    "    knn_indices = list(itertools.islice(sorted_distances_indices,k)) #Extracting the indices of the k-smallest distances\n",
    "\n",
    "    knn_labels = []\n",
    "    for i in knn_indices:\n",
    "      label = trained['Sentiment'][i] #Extracting the label of the instance by indexing it through the DataFrame.\n",
    "      knn_labels.append(label) #Appending the label to our labels list.\n",
    "\n",
    "    max_class = get_mode(knn_labels)\n",
    "    first_max = max_class\n",
    "    second_max = max(knn_labels)\n",
    "    if first_max == second_max:\n",
    "      check_tie = True\n",
    "    predicted_label = max_class\n",
    "    test['Predicted Label'][row_count] = predicted_label\n",
    "\n",
    "    row_count += 1\n",
    "\n",
    "  #Creating a frequency DataFrame that will store value counts for each tuple of instances. E.g (positive,positive = 309) and so on for all other seven instances.\n",
    "  testfreqdf = test.groupby([\"Sentiment\", \"Predicted Label\"]).size().reset_index(name=\"Frequency\")\n",
    "  testfreqdf\n",
    "\n",
    "  #Extracting values from the Frequency DataFrame and assigning to specific cells in the confusion matrix.\n",
    "  cmatrix['Gold Positive']['Predicted Positive'] = testfreqdf['Frequency'][8]\n",
    "  cmatrix['Gold Neutral']['Predicted Positive'] = testfreqdf['Frequency'][5]\n",
    "  cmatrix['Gold Negative']['Predicted Positive'] = testfreqdf['Frequency'][2]\n",
    "  cmatrix['Gold Positive']['Predicted Neutral'] = testfreqdf['Frequency'][7]\n",
    "  cmatrix['Gold Neutral']['Predicted Neutral'] = testfreqdf['Frequency'][4]\n",
    "  cmatrix['Gold Negative']['Predicted Neutral'] = testfreqdf['Frequency'][1]\n",
    "  cmatrix['Gold Positive']['Predicted Negative'] = testfreqdf['Frequency'][6]\n",
    "  cmatrix['Gold Neutral']['Predicted Negative'] = testfreqdf['Frequency'][3]\n",
    "  cmatrix['Gold Negative']['Predicted Negative'] = testfreqdf['Frequency'][0]\n",
    "\n",
    "  #Extracting all three True Positives from the matrix to measure accuracy.\n",
    "  TP = cmatrix['Gold Positive']['Predicted Positive']\n",
    "  TNT = cmatrix['Gold Neutral']['Predicted Neutral']\n",
    "  TN = cmatrix['Gold Negative']['Predicted Negative']\n",
    "  total = testfreqdf['Frequency'].sum()\n",
    "  accuracy = ((TP+TNT+TN)/total)*100\n",
    "  accuracy = round(accuracy,2)\n",
    "  accuracy_list.append(accuracy)\n",
    "\n",
    "  #Extracting all recalls from the matrix to measure macroaveraged recall.\n",
    "  recall_pos = cmatrix['Gold Positive']['Predicted Positive']/cmatrix['Gold Positive'].sum()\n",
    "  recall_neut = cmatrix['Gold Neutral']['Predicted Neutral']/cmatrix['Gold Neutral'].sum()\n",
    "  recall_neg = cmatrix['Gold Negative']['Predicted Negative']/cmatrix['Gold Negative'].sum()\n",
    "  macroaveraged_recall = ((recall_pos+recall_neut+recall_neg)/3)*100\n",
    "  macroaveraged_recall = round(macroaveraged_recall,2)\n",
    "  recall_list.append(macroaveraged_recall)\n",
    "\n",
    "  #Extracting all precisions from the matrix to measure macroaveraged precision.\n",
    "  precision_pos = cmatrix['Gold Positive']['Predicted Positive']/(cmatrix.iloc[0,0:3].sum())\n",
    "  precision_neut = cmatrix['Gold Neutral']['Predicted Neutral']/(cmatrix.iloc[1,0:3].sum())\n",
    "  precision_neg = cmatrix['Gold Negative']['Predicted Negative']/(cmatrix.iloc[2,0:3].sum())\n",
    "  macroaveraged_precision = ((precision_pos+precision_neut+precision_neg)/3)*100\n",
    "  macroaveraged_precision = round(macroaveraged_precision,2)\n",
    "  precision_list.append(macroaveraged_precision)\n",
    "\n",
    "  #Extracting all F1_scores from the matrix to measure macroaveraged F1_score.\n",
    "  F1_pos = (2*precision_pos*recall_pos)/(precision_pos+recall_pos)\n",
    "  F1_neut = (2*precision_neut*recall_neut)/(precision_neut+recall_neut)\n",
    "  F1_neg = (2*precision_neg*recall_neg)/(precision_neg+recall_neg)\n",
    "  F1_score = ((F1_pos + F1_neut + F1_neg)/3)*100  \n",
    "  F1_score = round(F1_score,2)\n",
    "  F1_list.append(F1_score)\n",
    "  \n",
    "\n",
    "  print(\"\\n\\nConfusion Matrix with k = {}:\\n\".format(k))\n",
    "  print(cmatrix)\n",
    "  print(\"\\nAccuracy with k = {0}: {1}%\".format(k,accuracy))\n",
    "  print(\"Macroaveraged Precision with k = {0}: {1}%\".format(k,macroaveraged_precision))\n",
    "  print(\"Macroaveraged Recall with k = {0}: {1}%\".format(k,macroaveraged_recall))\n",
    "  print(\"Macroaveraged F1-score with k = {0}: {1}%\".format(k,F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70a2c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_112/4185092973.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted Label'][row_count] = predicted_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix with k = 1:\n",
      "\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive           263          107           205\n",
      "Predicted Neutral            132          343           758\n",
      "Predicted Negative            77          165           871\n",
      "\n",
      "Accuracy with k = 1: 50.56%\n",
      "Macroaveraged Precision with k = 1: 50.6%\n",
      "Macroaveraged Recall with k = 1: 52.99%\n",
      "Macroaveraged F1-score with k = 1: 48.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_112/4185092973.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted Label'][row_count] = predicted_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix with k = 3:\n",
      "\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive           273          124           235\n",
      "Predicted Neutral            135          363           783\n",
      "Predicted Negative            64          128           816\n",
      "\n",
      "Accuracy with k = 3: 49.71%\n",
      "Macroaveraged Precision with k = 3: 50.83%\n",
      "Macroaveraged Recall with k = 3: 53.79%\n",
      "Macroaveraged F1-score with k = 3: 48.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_112/4185092973.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted Label'][row_count] = predicted_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix with k = 5:\n",
      "\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive           272          133           250\n",
      "Predicted Neutral            138          376           814\n",
      "Predicted Negative            62          106           770\n",
      "\n",
      "Accuracy with k = 5: 48.55%\n",
      "Macroaveraged Precision with k = 5: 50.64%\n",
      "Macroaveraged Recall with k = 5: 53.58%\n",
      "Macroaveraged F1-score with k = 5: 47.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_112/4185092973.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted Label'][row_count] = predicted_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix with k = 7:\n",
      "\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive           275          121           247\n",
      "Predicted Neutral            153          397           871\n",
      "Predicted Negative            44           97           716\n",
      "\n",
      "Accuracy with k = 7: 47.52%\n",
      "Macroaveraged Precision with k = 7: 51.42%\n",
      "Macroaveraged Recall with k = 7: 53.95%\n",
      "Macroaveraged F1-score with k = 7: 47.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_112/4185092973.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['Predicted Label'][row_count] = predicted_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix with k = 10:\n",
      "\n",
      "                   Gold Positive Gold Neutral Gold Negative\n",
      "Predicted Positive           275          112           252\n",
      "Predicted Neutral            158          424           893\n",
      "Predicted Negative            39           79           689\n",
      "\n",
      "Accuracy with k = 10: 47.52%\n",
      "Macroaveraged Precision with k = 10: 52.39%\n",
      "Macroaveraged Recall with k = 10: 54.92%\n",
      "Macroaveraged F1-score with k = 10: 47.42%\n"
     ]
    }
   ],
   "source": [
    "#Calling the function for each individual k\n",
    "cmatrix_measures(1,dists,test,cmatrix)\n",
    "cmatrix_measures(3,dists,test,cmatrix)\n",
    "cmatrix_measures(5,dists,test,cmatrix)\n",
    "cmatrix_measures(7,dists,test,cmatrix)\n",
    "cmatrix_measures(10,dists,test,cmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcfb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
