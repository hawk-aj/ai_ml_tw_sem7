{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3065c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e1e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the training and test datasets into their respective dataframes\n",
    "trained = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f55ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the stop_words.txt file and storing all the words in a list.\n",
    "stopwords = []\n",
    "with open('stop_words.txt','r') as file:    \n",
    "    for line in file:         \n",
    "        for word in line.split():            \n",
    "            stopwords.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c908955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@united 877 amsterdam ewr, 02.27.2015, 737-300.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united IT-problems link? #3thparty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united -today staff @ MSP took customer servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir yet receive assistance one agents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@SouthwestAir let change reservation online I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                              Tweet\n",
       "0   neutral    @united 877 amsterdam ewr, 02.27.2015, 737-300.\n",
       "1  negative                @united IT-problems link? #3thparty\n",
       "2  positive  @united -today staff @ MSP took customer servi...\n",
       "3  negative  @AmericanAir yet receive assistance one agents...\n",
       "4  negative  @SouthwestAir let change reservation online I'..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all stopwords from all the tweets in training data.\n",
    "trained[\"Tweet\"] = trained[\"Tweet\"].apply(lambda func: ' '.join(sw \n",
    "                                          for sw in func.split() \n",
    "                                          if sw not in stopwords))\n",
    "\n",
    "# Removing all stopwords from all the tweets in test data.\n",
    "test[\"Tweet\"] = test[\"Tweet\"].apply(lambda func: ' '.join(sw \n",
    "                                          for sw in func.split() \n",
    "                                          if sw not in stopwords))\n",
    "trained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306a7696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in Training Data: 15823\n",
      "Unique words in Test Data: 6973\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "train_unique = (list(set(trained['Tweet'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in training data's Tweet column\n",
    "train_unique_words = len(train_unique)\n",
    "\n",
    "#Test Data\n",
    "test_unique = (list(set(test['Tweet'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in test data's Tweet column\n",
    "test_unique_words = len(test_unique)\n",
    "\n",
    "print(\"Unique words in Training Data: {}\".format(train_unique_words))\n",
    "print(\"Unique words in Test Data: {}\".format(test_unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8db7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all special characters that are to be removed.\n",
    "special_chars = [\"!\",'\"',\"%\",\"&\",\"amp\",\"'\",\"(\",\")\", \"*\",\"+\",\",\",\"-\",\".\",\n",
    "                 \"/\",\":\",\";\",\"<\",\"=\",\">\",\"?\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "                 \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\",\"@\",\"#\",\"$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3edfebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trained['Tweet'] = trained['Tweet'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '') # Removing hyperlinks from all the tweets. They are not needed for classification.\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trained['Tweet'] = trained['Tweet'].str.replace('@[A-Za-z0-9]+', '') # Removing usernames from all the tweets.\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trained['Tweet'] = trained['Tweet'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '') # Removing hashtags, including the text, from all the tweets. Hashtags are useless since their words cannot be splitted with spaces.\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  trained['Tweet'] = trained['Tweet'].str.replace('\\d+', '') # Removing numbers from all the tweets. They will not assist in any way to improve the classification process.\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  trained['Tweet'] = trained['Tweet'].str.replace(c,'') # Removing all special characters from all the tweets\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['Tweet'] = test['Tweet'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '') # Removing hyperlinks from all the tweets\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['Tweet'] = test['Tweet'].str.replace('@[A-Za-z0-9]+', '') # Removing usernames from all the tweets.\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['Tweet'] = test['Tweet'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '') # Removing hashtags, including the text, from all the tweets\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test['Tweet'] = test['Tweet'].str.replace('\\d+', '') # Removing numbers from all the tweets\n",
      "C:\\Users\\aj240\\AppData\\Local\\Temp/ipykernel_24120/744368757.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  test['Tweet'] = test['Tweet'].str.replace(c,'') # Removing all special characters from all the tweets\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "trained['Tweet'] = trained['Tweet'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '') # Removing hyperlinks from all the tweets. They are not needed for classification.\n",
    "trained['Tweet'] = trained['Tweet'].str.replace('@[A-Za-z0-9]+', '') # Removing usernames from all the tweets.\n",
    "trained['Tweet'] = trained['Tweet'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '') # Removing hashtags, including the text, from all the tweets. Hashtags are useless since their words cannot be splitted with spaces.\n",
    "trained['Tweet'] = trained['Tweet'].str.replace('\\d+', '') # Removing numbers from all the tweets. They will not assist in any way to improve the classification process.\n",
    "\n",
    "for c in special_chars:\n",
    "    trained['Tweet'] = trained['Tweet'].str.replace(c,'') # Removing all special characters from all the tweets\n",
    "\n",
    "#Test Data\n",
    "test['Tweet'] = test['Tweet'].str.replace(r'http?://[^\\s<>\"]+|www\\.[^\\s<>\"]+', '') # Removing hyperlinks from all the tweets\n",
    "test['Tweet'] = test['Tweet'].str.replace('@[A-Za-z0-9]+', '') # Removing usernames from all the tweets.\n",
    "test['Tweet'] = test['Tweet'].str.replace(r'\\B#\\w*[a-zA-Z]+\\w*', '') # Removing hashtags, including the text, from all the tweets\n",
    "test['Tweet'] = test['Tweet'].str.replace('\\d+', '') # Removing numbers from all the tweets\n",
    "\n",
    "for c in special_chars:\n",
    "    test['Tweet'] = test['Tweet'].str.replace(c,'') # Removing all special characters from all the tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16960ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>amsterdam ewr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>ITproblems link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>today staff  MSP took customer service new le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>yet receive assistance one agents securing ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>let change reservation online Im wasting time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                              Tweet\n",
       "0   neutral                                    amsterdam ewr  \n",
       "1  negative                                   ITproblems link \n",
       "2  positive   today staff  MSP took customer service new le...\n",
       "3  negative   yet receive assistance one agents securing ne...\n",
       "4  negative     let change reservation online Im wasting time "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea577f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>jump DallasAustin market  News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Chicago seen seat A AA  So far great ride On ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>need bag bouncer Get together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Hey Jetblue stranded entire plane supposed go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>Big fail curbside baggage Pittsburgh charge  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                              Tweet\n",
       "0   neutral                    jump DallasAustin market  News \n",
       "1  positive   Chicago seen seat A AA  So far great ride On ...\n",
       "2  negative                      need bag bouncer Get together\n",
       "3  negative   Hey Jetblue stranded entire plane supposed go...\n",
       "4  negative   Big fail curbside baggage Pittsburgh charge  ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a912a4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words in Training Data: 12416\n",
      "Unique words in Test Data: 5814\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "train_unique = (list(set(trained['Tweet'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in training data's Tweet column\n",
    "train_unique_words = len(train_unique)\n",
    "\n",
    "#Test Data\n",
    "test_unique = (list(set(test['Tweet'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in test data's Tweet column\n",
    "test_unique_words = len(test_unique)\n",
    "\n",
    "print(\"Unique words in Training Data: {}\".format(train_unique_words))\n",
    "print(\"Unique words in Test Data: {}\".format(test_unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "404b9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained.to_csv('train_clean.csv')\n",
    "test.to_csv('test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52294910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
